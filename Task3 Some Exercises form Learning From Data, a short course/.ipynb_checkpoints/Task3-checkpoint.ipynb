{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814c17b6",
   "metadata": {},
   "source": [
    "# Some Exercises Chapter one (Learning from Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb9a14",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "Suppose that we use a perceptron to detect spam messages. Let's say that each email message is represented by the frequency of occurrence of keywords, and the output is if the message is considered spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b930731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33b4310b",
   "metadata": {},
   "source": [
    "#### (a) Can you thinkofsome keywords that will end up with a large positive weight in the perceptron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7fd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bf02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49fa06b7",
   "metadata": {},
   "source": [
    "#### (b) How about keywords that will get a negative weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be667687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c1e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "118aac79",
   "metadata": {},
   "source": [
    "#### (c) What parameter in the perceptron directly affects how many borderline messages end up being classified as spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c11543d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5127488",
   "metadata": {},
   "source": [
    "## 1.3 \n",
    "The weight update rule in (1.3) has the nice interpretation that it moves in the direction of classifying $x(t)$ correctly. \n",
    "\n",
    "$w(t+1)= w(t)+y(t)x(t)$. (1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ae480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1cb2f80",
   "metadata": {},
   "source": [
    "### (a) Show that $y(t)w^{T}(t)x(t) < 0$. [Hint: $x(t)$ is misclassified by $w(t)$.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c2eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2810b082",
   "metadata": {},
   "source": [
    "### (b)  Show that $y(t)w^{T}(t+1)x(t) > y(t)w^{T}(t)x(t)$. [Hint: Use (1.3).]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ffcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db93d51e",
   "metadata": {},
   "source": [
    "### (c) As far as classifying $x(t)$ is concerned, argue that the move from $w(t)$ to $w(t+ 1)$ is a move 'in the right direction'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bf89f",
   "metadata": {},
   "source": [
    "## 1.10 \n",
    "Here is an experiment that illustrates the difference between a single bin and multiple bins. Run a computer simulation for flipping 1,000 fair coins. Flip each coin independently times. Let's focus on 3 coins as follows: $c_1$ is the first coin flipped; $c_{rand}$ is a coin you choose at random; $c_{min}$ is the coin that had the minimum frequency of heads (pick the earlier one in case of a tie). Let $v_1$ , $v_{rand}$ and $v_{min}$ be the fraction of heads you obtain for the respective three coins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43038bd6",
   "metadata": {},
   "source": [
    "### (a) What is $μ$ for the three coins selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04ae97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab78846",
   "metadata": {},
   "source": [
    "### (b) \n",
    "Repeat this entire experiment a large number of times (e.g., 100, 000 runs of the entire experiment) to get several instances of $v_1$ , $v_{rand}$ and $v_{min}$ and plot the histograms of the distributions of $v_1$ , $v_{rand}$ and $v_{min}$. Notice that which coins end up being $c_{rand}$ and $c_{min}$ may differ from one run to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cbf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6564a46",
   "metadata": {},
   "source": [
    "### (c) Using (b), plot estimates for $\\mathbb{P}[|v-μ| > \\epsilon]$ as a function of $\\epsilon$, together with the Hoeffding bound $2e^{-2\\epsilon^{2}N}$ (on the same graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad2d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbcee90b",
   "metadata": {},
   "source": [
    "### (d) Which coins obey the Hoeffding bound, and which ones do not? Ex­ plain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226e9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a1788b0",
   "metadata": {},
   "source": [
    "### (e) Relate part (d) to the multiple bins in Figure 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a6928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97b05645",
   "metadata": {},
   "source": [
    "## 1.11\n",
    "We are given a data set 'D of25 training examples from an unknown target function j: Y, where =JRand ={-1,+1}. learn f, we use a simple hypothesis set = {h1, h2} where h1 is the constant function and h2 is the constant -1.We consider two learning algorithms, S (smart) and (crazy). S chooses the hypothesis that agrees the most with and chooses the other hy­ pothesis deliberately. Let us see how these algorithms perform out of sam­ ple from the deterministic and probabilistic points of view. Assume in the probabilistic view that there is a probability distribution on X, and let JID[f(x) = = p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d01da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461754aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
